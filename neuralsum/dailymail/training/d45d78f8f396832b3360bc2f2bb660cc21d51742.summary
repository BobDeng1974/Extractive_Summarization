http://web.archive.org/web/20111221134852id_/http://www.dailymail.co.uk/sciencetech/article-2073961/Supercomputer-runs-biggest-simulation-universe-took-20-days.html

by @entity0 last updated at 12:33 pm on 14th december 2011 the largest ever simulation of the universe has been run by the 26th most powerful computer in the world			2
researchers at the @entity6 in @entity7 used the @entity9 supercomputer for the task , which has @entity11 of disk space and over 26,232 processing cores – and it still needed 20 days to complete the task			1
in the end it analysed around 374 billion particles , which equates to an area around two thirds the size of the observable universe			1
@entity22 3 : the simulation enabled researchers to peer from a virtual @entity25 in the middle back in time to the early universe 12 billion years ago the purpose of the study - called @entity29 3 - was to run the birth and evolution of the universe to see if it ends up with the same properties as the one we see around us , including galactic clusters and super-clusters			1
by studying this virtual version , astronomers are better able to predict how the universe will change over time			2
they are also able to study in detail structures that are too old and distant to see with telescopes and matter that only exists in theory , such as acoustic baryon oscillations			0
these are huge clumps of frozen dark energy left over from the birth of the universe			0
astronomer dr @entity50 believes the project is extremely worthwhile			0
she told @entity52 : ' this is a mind - boggling , ambitious project			0
it will shed light on the past and future of our universe - and give us insights into the mysterious dark matter that makes up so much of our cosmos , and the unknown dark energy that drives it			0
' @entity66 above : the @entity9 supercomputer took 20 days to simulate the evolution of the universe from birth to the present day it ’s thanks to supercomputers such as the @entity74 that our understanding of the universe is growing at unprecedented rates			1
by comparison , a simulation of galaxies in 1970 by @entity81 at @entity82 analysed just 300 ‘ particles ’ , while in 2005 the millennium simulation looked at 10 billion particles			1
as @entity90 physics blogger @entity88 writes , that means that @entity91 is 8,800 times bigger .			0

@entity9 supercomputer has @entity94 of disc space
analysed 374 billion simulated ' particles '
@entity100 supercomputer took 20 days to complete task

@entity22:Horizon Run
@entity0:Ted Thornhill
@entity7:Seoul
@entity6:Korea Institute for Advanced Study
@entity11:157,392GB
@entity25:Earth
@entity66:Heavens
@entity9:Tachyon II
@entity29:Horizon Run
@entity100:Korean
@entity52:MailOnline
@entity82:Princeton University
@entity50:Heather Couper
@entity81:Jim Peebles
@entity88:KFC
@entity74:Tachyonii
@entity94:157,392GB
@entity91:Horizon Run 3
@entity90:MIT