http://web.archive.org/web/20150706062001id_/http://www.dailymail.co.uk/sciencetech/article-2874890/Are-robots-destined-EVIL-Moral-uncertainty-means-experts-never-able-program-machines-know-right-wrong.html

the likes of @entity1 and @entity2 have warned about the potential threats posed by artificial intelligence			0
and now a group of researchers has fuelled this debate , saying no matter what we teach a robot , it will never know right from wrong			2
ultimately they conclude robots ca n't determine what is the ‘ right ’ thing to do in certain situation , and instead will be unpredictable in their response to uncomputable moral dilemmas			1
researchers at @entity18 in @entity19 claim robots ( illustration shown ) can never be moral			1
in a study , they said the famous moral dilemma called the ' trolley problem ' prevents such action being programmed			1
as there is no ' correct ' answer , robots will always be unpredictable , they warn in their paper ‘ logical limitations to machine ethics with consequences to lethal autonomous weapons , ’ the group from @entity18 in @entity19 discussed the impending use of autonomous weapons			1
‘ lethal autonomous weapons promise to revolutionise warfare - and raise a multitude of ethical and legal questions , ’ they wrote			2
although there are several versions , one aspect of the problem involves a trolley running towards a group of five people , whom it will fatally injure if it is allowed to keep running			1
a person standing near the switch is given the option to divert the trolley towards just a single person			1
the right course of action to take in the scenario is a moral dilemma , but considering there is no absolute , correct solution , it poses a problem for the future artificial intelligence			1
namely , if they can not work out the right thing to do , they will simply choose seemingly at random			0
while it has been suggested that robots could be employed with a ‘ moral compass ’ , such as the @entity70 , the researchers said this will not be sufficient			1
this is due to something known as the halting problem , which states it is not possible to tell whether an arbitrary computer program will finish running eventually , or run forever			2
@entity76 , writing for @entity78 , said that how this relates to artificial intelligence is that ‘ algorithms do unexpected things ; software has bugs			0
’ he continued : ‘ an algorithm programmed to do the right thing might do the wrong thing			0
’ in the paper , the researchers give the example of the ‘ trolley problem ’			1
although there are several versions , one aspect of the problem involves a trolley running towards a group of five people , whom it will fatally injure if it is allowed to keep running			1
will humans and robots ever be able to co-exist ? teaching a robot right from wrong might turn out to be more difficult than we think , even if we were to program them with sets of pre-determined ethical instructions such as the @entity70			2
shown is humanoid robot @entity108 shaking hands in june 2013 recently @entity2 and @entity1 ( shown ) have both warned of the rise of artificial intelligence			0
the latter said that humanity faces an uncertain future as technology learns to think for itself and adapt to its environment			2
' the development of full artificial intelligence could spell the end of the human race , ' he said			0
our desire to create helpful digital assistants and self - driving vehicles could bring about our demise			2
professor @entity1 has warned that humanity faces an uncertain future as technology learns to think for itself and adapt to its environment			2
speaking at an event in @entity135 , the physicist told the @entity136 that : ' the development of full artificial intelligence could spell the end of the human race			0
' this echoes claims he made earlier in the year when he said success in creating @entity142 ' would be the biggest event in human history , [ but ] unfortunately , it might also be the last			1
' he argues that developments in digital personal assistants @entity149 , @entity150 and @entity151 are merely symptoms of an it arms race which ' pale against what the coming decades will bring			0
' a person standing near the switch is given the option to divert the trolley towards just a single person			2
the right course of action to take in the scenario is a moral dilemma , but considering there is no absolute , correct solution , it poses a problem for the future artificial intelligence			1
namely , if they can not work out the right thing to do , they will simply choose seemingly at random			0
this means that artificial intelligence will always have an air of unpredictability to it ; no matter how it is programmed			0
and even with the strictest and safest level of morality , there are some scenarios it simply ca n't handle			0
the scenario is reminiscent of @entity184 's @entity183 , in which a robot goes rogue and is accused of killing a dr. @entity187 , the co-founder of story 's @entity188 ( @entity188 )			0
to deal with the potential problem , the researchers list a number of suggestions that all future robots should be programmed with			1
one is that no robot should be designed with the sole or primary task of killing or harming humans			0
the manufacturer of a robot should also be held accountable for any actions it takes , ‘ to comply with existing laws and fundamental rights and freedoms			0
’ ultimately , though , future @entity142 may require even more checks and balances - or self - imposed limitations - to prevent robots having to deal with moral dilemmas			1
the scenario is reminiscent of @entity184 's @entity183 , ( film adaptation starring @entity212 left and @entity216 right ) in which a robot ( centre ) goes rogue and is accused of killing @entity217 , the co-founder of story 's @entity188 ( @entity188 )			0

researchers in @entity19 say it is *impossible* for robots to ever have morals
in a study they claim the famous ' trolley problem ' prevents such action
this famous thought *experiment* involves using a switch to save the lives of many in *favour* of a few
but there is no ' correct ' answer - so robots will always be unpredictable
follows warning from prominent *scientists* that @entity142 is a threat to humanity

@entity188:USR
@entity2:Elon Musk
@entity1:Stephen Hawking
@entity150:Google Now
@entity142:AI
@entity212:Bridget Moynahan
@entity183:iRobot
@entity184:Isaac Asimov
@entity149:Siri
@entity19:Germany
@entity187:Alfred Lanning
@entity216:Will Smith
@entity108:Roboy
@entity217:Dre Alfred Lanning
@entity76:Michael Byrne
@entity18:Darmstadt University of Technology
@entity135:London
@entity151:Cortana
@entity136:BBC
@entity70:Geneva Convention
@entity78:Vice