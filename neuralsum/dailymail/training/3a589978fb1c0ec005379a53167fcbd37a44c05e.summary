http://web.archive.org/web/20150609171442id_/http://www.dailymail.co.uk/news/article-2322892/The-racist-map-America-Tweets-analyzed-offensive-keywords-reveal-hateful-parts-US-people-hated.html

racism , homophobia and general intolerance are not unique to any particular region of the @entity4 - that is the conclusion that @entity6 college students have reached after mapping out hate speech based on @entity9 posts			1
undergraduate students at @entity11 analyzed 150,000 geocoded tweets sent out between june 2012 and april 2013 containing 10 pre-selected hate words in three categories : @entity0 , homophobia and disability			1
after processing the data aggregated by the @entity18 , the team comprised of three students in dr @entity20 ’ advance cartography class produced an interactive map as part of @entity24 project			0
mapping bigotry : undergraduate students at @entity11 analyzed 150,000 geocoded tweets containing 10 pre-selected hate words in three categories : racism , homophobia and disability disturbing findings : researchers discovered 41,306 tweets containing the word ' n * * * * * , ' which were not concentrated in any single region of the @entity4 the avoid the pitfall of an algorithm automatically classifying a tweet as negative if it contains a ' hate word , ' the organizers of the project relied on students to read the entirety of the message for context before deciding if is tweet is in fact hateful			1
only words unequivocally deemed as ‘ hate speech ’ were used in the creation of the map			0
that way , a phrase like ‘ dykes on bikes , ’ for example , was left out of the data used in the project because it referenced a gay pride event in @entity59			0
to produce the map , all tweets containing each ' hate word ' were aggregated to the county level and normalized by the total @entity9 traffic in each county			0
human touch : since an algorithm would automatically classify a tweet as negative if it contains a ' hate word , ' the organizers of the project had the students to read the entirety of the message before deciding if is hateful @entity4 's true colors : where there is a larger proportion of negative tweets referencing a particular ' hate word ' the region appears red ; where the proportion is moderate , the area is shaded a pale blue where there is a larger proportion of negative tweets referencing a particular ' hate word ' the region appears red on the map ; where the proportion is moderate , the word was used less and appears a pale blue on the map			2
areas without shading indicate places that have a lower proportion of negative tweets relative to the national average			0
researchers discovered 41,306 tweets containing the word ‘ n * * * * * ’ , 95,123 referenced ‘ homo ’ , among other terms			2
tweets that included the slur ‘ n * * * * * ’ used for african - americans were not concentrated in any single region in the @entity4 ; instead , there are a number of pockets of concentration , including @entity110 , where 31 users sent out 41 tweets referencing the word , and @entity114 , @entity115 , where there were 22 tweets containing the slur			1
pockets of hatred : most of the tweets containing the word ' wetback ' - an offensive term of illegal @entity126 immigrants - came from several parts of @entity128 perhaps the most interesting concentration comes for references to ‘ wetback ’ - a derogatory term used for illegal @entity126 immigrants			1
most tweets containing the offensive term came from several parts of @entity128 , which surprisingly are not even close to the @entity126 - @entity4 border			2
under the category of racism , besides ' n * * * * * and ‘ wetback ’ students also looked at the usage of such slurs as ' chink ' and ' gook ' refering to @entity144 and @entity145 , respectively , and ' spick , ' which is an offensive term for @entity147			1
the word ' chink ' was concentrated in @entity149 , where 19 users referenced the slurs in a total of 23 tweets .			0

the project @entity156 was created by cartography students at @entity11
students analyzed 150,000 tweets containing hate words sent between june 2012 - april 2013
researchers looked at usage of 10 slurs in three categories : racist , homophobic and disability
use of offensive term n * * * * * was not concentration in any single region , but had pockets of concentration in @entity110 and @entity115

@entity144:Chinese
@entity145:Korenas
@entity20:Monica Stephens
@entity0:Racism
@entity6:California
@entity11:Humboldt State University
@entity4:American
@entity9:Twitter
@entity149:Central Minnesota
@entity18:DOLLY Project
@entity24:The Geography of Hate
@entity115:Indiana
@entity147:Hispanics
@entity128:Texas
@entity110:Iowa
@entity126:Mexican
@entity59:San Francisco
@entity114:Fountain
@entity156:Geography of Hate