http://web.archive.org/web/20140130055315id_/http://www.dailymail.co.uk/sciencetech/article-2548207/Is-Facebook-making-MORE-political-Researchers-notice-friends-politically-aligned-with.html

by @entity0 published : 13:34 est , 29 january 2014 updated : 13:38 est , 29 january 2014 @entity3 can boost our political leanings dramatically - and cause us to ignore friends we do n't agree with , researchers have claimed			1
a @entity8 study found users tend to stick in their own circles and become more polarised			1
it also claimed @entity3 's own algorithms should be tweaked to make more partisan stories appear			1
the @entity8 study found users tend to stick in their own circles and ignore friends whose beliefs they do n't agree with			1
the study surveyed more than 100 politically active @entity3 users in the spring of 2013 amid debates about budgets cuts , gay marriage and gun control regulations			1
the majority of participants were liberal , female and under the age of 40 , mirroring the traditional @entity3 user			2
more than 70 percent said they do n’t talk about politics with their friends with different opinions			2
when they saw something they did n’t agree with , 60 percent said they ignored it and did n’t comment			0
when they did , sometimes it made the person question the relationship and disassociate and from the friend			0
' people are mainly friends with those who share similar values and interests			1
' they tend to interact with them the most , a phenomenon called homophily , ' said @entity46 , the @entity47 student who led the study			2
' but that means they rarely interact with the few friends with differing opinions			0
' as a result , they are n’t exposed to opposing viewpoints			0
' people who think the majority of their friends have differing opinions than their own engage less on @entity3 , the researchers discovered			1
for those who choose to stay logged in and politically active , the research found that most tend to stick in their own circles , ignore those on the other side and become more polarized			2
the study also found @entity3 may be partly to blame - as its algorithms learn what we like			1
@entity46 suggests that the social media site should sprinkle in a few status updates on both sides of political issues			0
that would expose people to different opinions , which are typically held by weak ties			0
' designing social media toward nudging users to strengthen relationships with weak ties with different viewpoints could have beneficial consequences for the platform , users and society , ' she said			0
people who think the majority of their friends have differing opinions than their own engage less on @entity3 , the researchers discovered			1
the study surveyed more than 100 politically active @entity3 users in the spring of 2013 amid debates about budgets cuts , gay marriage and gun control regulations			1
the majority of participants were liberal , female and under the age of 40 , mirroring the traditional @entity3 user			2
more than 70 percent said they do n’t talk about politics with their friends with different opinions			0
when they saw something they did n’t agree with , 60 percent said they ignored it and did n’t comment			0
when they did , sometimes it made the person question the relationship and disassociate and from the friend			0
' even though people could simply unfriend someone with different opinions , and there were certainly those who did that , there were many relationships that were able to be maintained , ' said @entity46			0
' through a combination of behaviors on @entity3 like hiding , tuning out , logging off or avoiding certain conversations , people negotiated around those differences to stay connected			2

study *dubbed* @entity3 ' the great *divider* '
claims people stick with their own circles of politically similar friends
says @entity3 's algorithms could be more partisan

@entity3:Facebook
@entity46:Grevet
@entity0:Mark Prigg
@entity8:Georgia Institute of Technology
@entity47:Georgia Tech Ph.D.