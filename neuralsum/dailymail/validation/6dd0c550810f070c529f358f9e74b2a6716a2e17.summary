http://web.archive.org/web/20150720055026id_/http://www.dailymail.co.uk/sciencetech/article-2977092/Control-phone-SEVEN-FEET-away-Ultrasound-technology-lets-play-music-selfies-unlock-phone-wave-hand.html

swiping through the air to control items on a screen conjure up images of the sci - fi technology seen in minority report			2
but a @entity8 firm has not only designed the system using an everyday smartphone , it has designed it to work from up to seven feet ( 2 metres ) away			0
the system tracks a user ’s hands movements using ultrasound to skip through images , play and pause videos and music , take selfies and control characters in online games			1
ultrasound signals sent through the air from speakers in smartphones and tablets bounce against a user ’s hand and are recorded by standard microphones			1
@entity23 ’ technology uses these signals to recognises hand gestures and uses them to move objects on a screen			1
the company compared it to the way bats use echolocation to navigate			1
gestures can be recognised from all sides of the device at 180 degrees			0
during @entity25 ’s demonstration , @entity23 ’ vice president of product development , @entity21 showcased how the technology can be used to show or hide the controls on @entity29 videos			2
dubbed @entity31 , the system was built by experts at @entity8 - based @entity23			2
ultrasound signals sent through the air from speakers in smartphones and tablets bounce against a user ’s hand and are recorded by standard microphones			1
@entity23 ’ technology uses these signals to recognises hand gestures and uses them to move objects on a screen			1
the company compared it to the way bats use echolocation to navigate			1
gestures can be recognised from all sides of the device at 180 degrees			0
he revealed how photos can be moved and managed using slow or fast swipes left and right , how an on - screen octopus could be controlled on a mobile game by moving his hand up and down , and taking selfies by virtually tapping a shutter button			0
and on a tablet , a music app and playback was controlled by virtually pressing the play button			0
a previous version , which measured gestures from 19 inches ( 50cm ) away , was showcased at this year ’s @entity88 in @entity89 in january			0
this demo introduced @entity91 ( @entity92 ) which lets mobiles and tablets display different content depending on the location and distance a user ’s hand is from the device			1
by using technology that is already inside smartphones along with software that can sit on top of existing operating systems , @entity23 hopes to launch the technology in handsets later this year			0
science fiction to reality : the technology that involves swiping through the air to control items on a screen conjures up images of the futuristic world seen in minority report ( scene pictured ) @entity23 ’ technology uses these signals to recognises hand gestures and uses them to move objects on a screen			1
the company compared it to the way bats use echolocation to navigate ( demo handset pictured ) mr @entity21 said the company had already partnered with two manufacturers but did n’t reveal which ones			2
‘ with @entity23 ’ gesture recognition technology the entire zone above and around a mobile device becomes interactive and responsive to the smallest gesture , ’ said the firm			0
‘ the active area is 180 degrees around the device made possible by ultrasound [ and ] @entity23 delivers the largest interaction space for consumer electronic devices while using very low power			0
’ mr @entity21 added that the interaction space can also be customised by device manufacturers or software developers depending on how they want it to be used .			0

the system tracks a users hands movements using ultrasound
gestures can skip through images , play videos and take selfies
it can also control characters in online games or control music
ultrasound signals sent through the air from speakers in smartphones and tablets bounce against a user ’s hand and are recorded by microphones
@entity23 uses these signals to recognise hand gestures
the company compared it to the way bats use echolocation to navigate

@entity31:Ultra-Fast Ultra-Far Interaction
@entity23:Elliptic Labs
@entity21:Strutt
@entity25:MailOnline
@entity8:Norway
@entity29:YouTube
@entity88:Consumer Electronics Show
@entity89:Las Vegas
@entity92:MLI
@entity91:Multi Layer Interaction