http://web.archive.org/web/20150720082417id_/http://www.dailymail.co.uk/sciencetech/article-2979554/Do-pass-human-Facebook-develops-quiz-sort-robots-people-s-surprisingly-hard.html

our ability to answer questions currently separates us from machines in the world of artificial intelligence			1
but researchers are working on algorithms to give computers this skill too			2
now , scientists at @entity11 have come up with questions that they say artificially intelligent machines must answer , if they can ever match human brainpower – but some of them are a bit tricky , meaning some people may fail them too			1
scientists at @entity11 ( logo shown ) have come up with questions that they say artificially intelligent machines must answer if they can ever match human brainpower – but some of them are a bit tricky , meaning some people may fail them too the team from the social media firm ’s @entity24 in @entity26 have come up with a list of 20 questions to separate humans from robots , because they say ‘ many existing learning systems can currently not solve them			1
’ they test different types of reasoning and the ability to process language			1
1 ) the first question of the 20 listed in the research paper was the simplest for a computer to answer			2
it is : @entity43 is in the playground @entity45 is in the office where is @entity43 ? 2 ) a harder example for a computer to answer is a question that requires it to differentiate three separate arguments , such as : @entity53 gave the cake to @entity55			0
@entity55 gave the cake to @entity57			0
@entity58 was given the milk by @entity55			0
who gave the cake to @entity55 ? who did @entity55 give the cake to ? what did @entity58 receive ? who gave the milk ? 3 ) another task tested a machine 's ability to perform simple counting operations by asking about the number of objects			0
for example : @entity74 picked up the football			0
how many objects is @entity80 ? 4 ) basic deduction skills were tested by questions such as : sheep are afraid of wolves			2
cats are afraid of dogs			0
mice are afraid of cats			0
what is @entity92 of ? 5 ) and reasoning about size was tested by this question : the football fits in the suitcase			0
the suitcase fits in the cupboard			0
the box of chocolates is smaller than the football			0
will the box of chocolates sit in the suitcase ? the intelligent computers were tested on 20 questions in total , but none of them got a perfect score			1
the answers to the five examples listed , are shown above the sometimes tricky questions test different types of reasoning and the ability to process language			1
a stock image of a perplexed person is shown some of the questions require machines to recall facts , while others need reasoning , or to count the number of objects , expressed in a written passage			1
the researchers say that humans should be able to score full marks			1
while you may have got one answer wrong , none of the seven computer learning programmes that @entity11 tested got all 20 questions right			1
the experiment was designed to test whether a machine can answer questions ‘ via chaining facts , simple induction , deduction and many more , ’ the study published on @entity143 says			2
scientists are keen to create this ability so that humans can talk fluently with machines , which could lead to robots looking after the elderly and more intelligent websites , for example			2
the paper says : ‘ one long - term goal of machine learning research is to produce methods that are applicable to reasoning and natural language , in particular building an intelligent dialogue agent			1
’ the experts aim to ‘ classify these tasks into skill sets , so that researchers can identify ( and then rectify ) the failings of their systems			0
’ the results of the test show that humans are still ahead of the game when it comes to interpreting the world ’s subtleties and language			1
the questions are written in very clear and simple terms so there is still a way to go before computers catch us up .			0

@entity180 was developed by experts at @entity11 to test machines with @entity24
it 's comprised of 20 questions testing reasoning and language skills
humans are expected to get a full score , with *careful* *consideration*
none of the @entity24 algorithms managed this showing more research is needed

@entity53:Mary
@entity26:New York
@entity11:Facebook
@entity24:AI
@entity143:arXiv
@entity180:Test
@entity80:Daniel holding
@entity45:Bob
@entity57:Bill
@entity74:Daniel
@entity55:Fred
@entity43:John
@entity89:Gertrude
@entity58:Jeff
@entity92:Gertrude afraid