http://web.archive.org/web/20140318092238id_/http://www.dailymail.co.uk/sciencetech/article-2575495/Turn-mobile-EYEphone-App-lets-blind-people-surroundings-converting-photos-SOUND.html

by @entity0 published : 06:32 est , 7 march 2014 updated : 10:50 est , 7 march 2014 a breakthrough technology that helps blind people ' see ' the world around them using sound is now available in a smartphone app. @entity9 system converts images taken on a mobile into ' soundscapes ' by assigning different musical notes and pitches to different shapes			1
for example , a diagonal line - such as staircase - is converted to a string of rising musical notes			1
the app , available on @entity22 , uses the phone 's camera to record scenes and landscapes , and teaches users how to identify which sounds go with which shapes			1
there is even an accompanying app called @entity33 that adds colour to these shapes			0
@entity9 system converts images into ' soundscapes ' by assigning different musical pitches to different shapes			1
for example , a diagonal line is converted to a string of rising musical notes			1
the app is available on @entity22 , pictured , and explains how users can train themselves to identify the shapes during tests , head - mounted cameras were attached to the blind participants before being wired up to a computer and microphone			2
as the participants moved around the room , the camera took a photo and converted into a ' soundscape '			0
it uses pitch for height and loudness for brightness by scanning the room from left to right			0
a rising bright line is converted into a rising tone , a bright spot - such as a lamp - is a beep , a brightly filled rectangle - such as a window during daylight - becomes a noise burst and a vertical grid - such as waffle or trellis - is converted into a rhythm			0
users are trained to identify which pitch relates to which height , for example			0
they then listen to , and interpret , the visual information coming from the camera - effectively ' seeing ' with sounds			0
after being taught how to use the technology , blind people could use the devices to learn to read , with sounds representing visual images of letters , for example			1
the @entity33 app uses the same principles , but additionally assigns different pitches to colours			0
@entity9 system was created by @entity93 engineer @entity92 in 1992			1
it uses pitch for height and loudness for brightness by scanning the room from left to right			0
a rising bright line is converted into a rising tone , a bright spot - such as a lamp - is a beep , a brightly filled rectangle - such as a window during daylight - becomes a noise burst and a vertical grid - such as waffle or trellis - is converted into a rhythm			0
since 2007 , neuroscientist professor @entity112 from the @entity113 has been training blind people how to use this technology			1
with around 70 hours training , professor @entity112 's participants recognise the presence of a human form			1
they are also able to detect the exact posture of the person in an image , and imitate it			0
using brain scans , professor @entity112 was able to establish the outlines and silhouettes of bodies cause the visual cortex in his participants ' brains - an area specifically dedicated in sighted people to processing body shapes - to light up with activity			1
@entity9 for @entity22 app makes this technology widely available			1
it uses augmented reality to convert live camera views to soundscapes for the totally blind through sensory substitution and computer vision			2
using @entity141 , researchers have also created @entity33 for @entity142 , pictured			2
it translates black and white images created by @entity9 into colour			2
colours are represented by different musical instruments - higher pixels are translated into higher notes while lower pixels are translated into lower notes on the same instrument researchers first taught people to perceive simple dots and lines			0
then those individuals learned to connect the lines with junctions or curves , gradually working up to more and more complex images , pictured the app also features a talking colour identifier , talking compass , talking face detector and a talking gps locator , while @entity168 visual search and @entity169 can be launched from @entity9 for @entity22 app by tapping the left or right screen edge			1
in professor @entity112 's most recent work , he has taken this a step further and created the @entity33 app for @entity178 devices			1
it uses an algorithm to translate the original black and white images created by @entity9 into colour			0
colours are represented using different musical instruments - higher pixels of an image are translated into higher notes on a given musical instrument , for example , higher pitches on the piano , trumpet or the violin , while lower pixels of an image are translated into lower notes on the same instrument			0
video : how the @entity9 technology appears to blind people the researchers from the @entity113 first taught people to perceive simple dots and lines			1
then those individuals learned to connect the lines with junctions or curves , gradually working up to more and more complex images			0
professor @entity112 's team taught congenitally blind adults , meaning adults who were born blind , to use what 's called sensory substitution devices ( @entity215 )			1
for example , when a person uses a visual - to - auditory @entity215 , images from a video camera are converted into ' soundscapes ' that represent the images			0
this allows the user to listen to and then interpret the visual information coming from the camera , in that way ' seeing ' with sounds			0
after being taught how to use the @entity215 , blind people could use the devices to learn to read , with sounds representing visual images of letters			2
this skill involved a region of the brain called the @entity236 ( @entity236 ) , which in sighted people is activated by seeing and reading letters ( pictured ) after only tens of hours of training , blind people 's @entity236 showed more activation for letters than for any of the other visual categories tested			1
pixels closer to the left side of the image are heard before pixels closer to the right side of the picture letting blind people determine shapes , colours and the position of items			2
the research has been reported in @entity256 journal @entity257			0
' the idea is to replace information from a missing sense by using input from a different sense , ' explained professor @entity112			2
' it 's just like bats and dolphins use sounds and echolocation to ' see ' using their ears			0
' ' imagine for instance a diagonal line going down from left to right ; if we use a descending musical scale - going on the piano from right to left - it will describe it nicely , " continued professor @entity112 's colleage @entity277			1
' and if the diagonal line is going up from left to right , then we use an ascending musical scale			2

@entity9 technology was developed by engineer @entity92 in 2007
it turns images into ' soundscapes ' where shapes produce different noises
for example , a diagonal line is converted to a string of rising musical notes
professor @entity112 has been training blind people to see using @entity141
@entity9 @entity22 app uses a phone 's camera to record views and scenes
the @entity142 app uses @entity141 to help blind people see colour
colours are assigned different pitches in the same way shapes are

@entity22:Android
@entity215:SSDs
@entity33:EyeMusic
@entity0:Victoria Woollaston
@entity236:VWFA
@entity141:vOICe
@entity142:EyeMusic iOS
@entity178:iOS
@entity9:The vOICe
@entity169:Google Goggles
@entity92:Peter Meijer
@entity113:Hebrew University of Jerusalem
@entity112:Amir Amedi
@entity256:Cell Press
@entity257:Current Biology
@entity277:Ella Striem-Amit
@entity93:Dutch
@entity168:CamFind